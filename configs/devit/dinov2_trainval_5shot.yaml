driver: torch
device: "cuda"

workdir:
  path: "/tmp/fsl/sam_vitb_coco2017/"
  unique: False

distributed:
  backend: nccl
  type: single  # single or multiple
  nproc_per_node: 4
  single:
    init_method: tcp://127.0.0.1:23456

models:
  devit_dinov2:
    model_name: "dinov2_vitb14"
    roi_pool_size: 7
    all_classes_fn: "../data/coco/all_classes.txt"
    seen_classes_fn: "../data/coco/seen_classes.txt"
    prototype_file: "/root/krishneel/Downloads/fsl/prototypes/dinov2/fs_coco14_trainval_base_5shot.vitb14.pkl"
    background_prototype_file: "/root/krishneel/Downloads/fsl/prototypes/dinov2/background_prototypes.vitb14.pth"

datasets:
  dataloader:
    batch_size: 1
    num_workers: 0
    shuffle: False
    pin_memory: True
    collate_fn: "collate_data_instances"
  coco:
    train:
      bucket_name: &bucket "sr-shokunin"
      root: "perception/datasets/coco/train2017"
      # anno_fn: "perception/datasets/coco/annotations/instances_val2017.json"
      anno_fn: "/root/krishneel/Downloads/fs_coco17_base_train.json"

transforms:
  train:
    engine: "torchvision.transforms"
    ConvertFormatBoundingBox:
      old_fmt: "XYWH"
      new_fmt: "XYXY"
    # Resize:
    #   size: [896, 896]
    ResizeToDivisible:
      factor: 14
    PadToSize:
      size: 896
    Normalize:
      mean: [0.48145466, 0.4578275, 0.40821073]
      std: [0.26862954, 0.26130258, 0.27577711]

solvers:
  engine: "torch.optim"
  snapshot: 5000

  SGD:
    lr: 0.001
    momentum: 0.5
  schedulers:
    StepLR:
      step_size: 10
      gamma: 0.1

io:
  checkpoint:
    engine: 's3_writer'
    bucket_name: *bucket
    root: "perception/models/fsl/sam_vitb_coco17_5shot/"

build:
  devit_dinov2:
    dataset: "coco"
    weights: "/root/krishneel/Downloads/fsl/weights/dinov2_trainval_5shot.pth"
    train:
      solver: "SGD"
      scheduler: "StepLR"
      epochs: 10

  model: "devit_dinov2"
