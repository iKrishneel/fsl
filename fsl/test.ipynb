{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febb403-c61e-4ae8-8976-ecab9bcc5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# !pip install git+https://github.com/openai/CLIP timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cca730-6395-49ad-a050-3131d3573df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from igniter.builder import build_engine\n",
    "from igniter.main import get_full_config\n",
    "\n",
    "from fsl.models.meta_arch import build_sam_fsod\n",
    "from fsl.models.meta_arch import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35d2c2-0a87-449c-91ec-1a894f366e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../configs/devit/resnet_trainval_30shot.yaml'\n",
    "# config_file = '../configs/devit/devit_dinov2_trainval_xshot.yaml'\n",
    "\n",
    "cfg = get_full_config(config_file)\n",
    "# cfg = OmegaConf.load(config_file)\n",
    "# print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "cfg.datasets.dataloader.batch_size = 1\n",
    "cfg.datasets.dataloader.num_workers = 1\n",
    "cfg.datasets.dataloader.shuffle=False\n",
    "cfg.options.train = False\n",
    "cfg.options.eval = True\n",
    "\n",
    "# cfg.models.devit_dinov2_fsod.prototype_file=\"/root/krishneel/Downloads/fsl/prototypes/devit_dinov2_fsod/fs_coco_trainval_novel_30shot.pkl\"\n",
    "# cfg.models.devit_dinov2_fsod.background_prototype_file=\"/root/krishneel/Downloads/fsl/prototypes/devit_dinov2_fsod/panoptic_train2017_only_stuffs.pkl\"\n",
    "# cfg.models.devit_dinov2_fsod.background_prototype_file=None\n",
    "\n",
    "cfg.build.resnet_fsod.weights=\"s3://sr-shokunin/perception/models/fsl/resnet_fsod_coco17_30shot/model_0000020.pt\"\n",
    "# cfg.build.sam_fsod.weights = \"s3://sr-shokunin/perception/models/fsl/sam_vitb_coco17_30shot/model_0000005.pt\"\n",
    "# cfg.build.dinov2_fsod.weights = \"s3://sr-shokunin/perception/models/fsl/dinov2_vitb_coco17_5shot/model_0000009.pt\"\n",
    "\n",
    "# cfg.build.devit_dinov2_fsod.weights = \"s3://sr-shokunin/perception/models/fsl/devit_dinov2/model_0000005.pt\"\n",
    "# cfg.build.model = \"dinov2_fsod\"\n",
    "cfg.build.resnet_fsod.mode = \"val\"\n",
    "\n",
    "engine = build_engine(cfg)\n",
    "print(OmegaConf.to_yaml(cfg.build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee93157-9109-41aa-85bd-d7256a367123",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "engine._model.eval().to(torch.float16)\n",
    "\n",
    "# print(engine._model.classifier.bg_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca4f17-e960-436d-beab-9806d02bd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = max([len(iid) for iid in engine._model.classifier._all_cids]) + 1\n",
    "gt_labels = lambda indices: [engine._model.classifier._all_cids[i] for i in indices]\n",
    "\n",
    "def accuracy(scores, gt_names, topk = 1):\n",
    "    _, indices = torch.topk(scores, topk, dim=1)\n",
    "    pred_labels = [gt_labels(index) for index in indices]\n",
    "\n",
    "    count = 0.0\n",
    "    for gt_name, labels in zip(gt_names, pred_labels):\n",
    "        count += 1 if gt_name in labels else 0\n",
    "    return count / len(gt_names)\n",
    "\n",
    "def print_labels(scores, targets, k = 2):\n",
    "    gt_names = targets[0]['gt_proposal'].labels\n",
    "    _, indexes = torch.topk(scores, k, dim=1)\n",
    "    \n",
    "    for name, i in zip(gt_names, indexes.cpu().numpy()):\n",
    "        string = name.ljust(size) + \" | \" + \"\".join([n.ljust(size) for n in gt_labels(i)])\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9111b4d-a334-48fd-af46-372d2be5487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_top1, acc_top5 = 0.0, 0.0\n",
    "progress_bar = tqdm(total=len(engine._dataloader), desc=\"Processing\", position=0, leave=True)\n",
    "\n",
    "for k, (images, targets) in enumerate(engine._dataloader, 1):\n",
    "    with torch.no_grad():\n",
    "        output, _ = engine._model(images, targets)\n",
    "    scores = output['scores']\n",
    "    # gt_names = targets[0]['gt_proposal'].labels\n",
    "    gt_names = [target['gt_proposal'].labels for target in targets]\n",
    "    gt_names = [item for sublist in gt_names for item in sublist]\n",
    "\n",
    "    t1 = accuracy(scores, gt_names, topk=1)\n",
    "    t5 = accuracy(scores, gt_names, topk=5)\n",
    "\n",
    "    acc_top1 += (t1 - acc_top1) / k\n",
    "    acc_top5 += (t5 - acc_top5) / k\n",
    "\n",
    "    # print(\"\\nImage ID: \", targets[0]['gt_proposal'].image_id)\n",
    "    # print_labels(scores, targets, k=5)\n",
    "    progress_bar.set_description(f\"Top 1: {acc_top1:.3f} | Top 5 {acc_top5:.3f}\")\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "print(\"\\nTop 1: \", acc_top1, \"Top 5: \", acc_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b453a-8d24-4867-96a9-f74baf3139d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = scores.argmax(1).cpu().numpy().tolist()\n",
    "print(gt_labels(indices), gt_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be479b0d-6711-44dc-9b12-3f337ca3e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine._model.classifier._all_cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca69b41-5c0d-4974-ac7e-3ffcc2ba8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsl.datasets.s3_coco_dataset import *\n",
    "from igniter.registry import dataset_registry\n",
    "from igniter.builder import build_dataloader\n",
    "from omegaconf import OmegaConf\n",
    "from igniter.builder import build_engine\n",
    "from igniter.main import get_full_config\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "c = '../configs/devit/prototypes/foreground_prototypes.yaml'\n",
    "cfg = get_full_config(c)\n",
    "cfg.build.model = 'devit_dinov2_fsod'\n",
    "cfg.datasets.dataloader.shuffle = True\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg.build))\n",
    "\n",
    "dl = build_dataloader(cfg, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f258c5-140d-487c-9390-5b6d89f5e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, target) in enumerate(dl):\n",
    "\n",
    "    print(target)\n",
    "    \n",
    "    im = image[0].permute(1, 2, 0).cpu().numpy()\n",
    "    im = cv.cvtColor(im, cv.COLOR_RGB2BGR)\n",
    "    im = cv.cvtColor(im, cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    for bb in target[0]['bboxes']:\n",
    "        x1, y1, x2, y2 = bb.int().cpu().numpy()\n",
    "        cv.rectangle(im, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "    plt.imshow(im); plt.show()\n",
    "\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cec5b0-f945-4724-86b6-c57acd424c5c",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d9624-5a7f-4e38-947b-f8a1764db5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_tsne(prototype):\n",
    "    high_dim_data = prototype.normalized_embedding.cpu().numpy()\n",
    "    tsne = TSNE(n_components=3, random_state=256)  # 3 components for 3D visualization\n",
    "    low_dim_data = tsne.fit_transform(high_dim_data)\n",
    "\n",
    "    # Initialize t-SNE model and fit_transform the high-dimensional data\n",
    "    tsne = TSNE(n_components=2, random_state=42)  # 2 components for 2D visualization\n",
    "    low_dim_data = tsne.fit_transform(high_dim_data)\n",
    "\n",
    "    # Plot the 2D t-SNE representation\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(low_dim_data[:, 0], low_dim_data[:, 1], marker='o', c='b', edgecolors='k')\n",
    "    plt.title('t-SNE Visualization of High-dimensional Data')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_distance(prototype):\n",
    "    data = prototype.normalized_embedding.float().cpu()\n",
    "    labels = prototype.labels\n",
    "\n",
    "    indices = np.argsort(labels)\n",
    "    labels = np.array(labels)[indices]\n",
    "    data = data[indices]\n",
    "\n",
    "    # Calculate pairwise distances using Euclidean distance for demonstration\n",
    "    expanded_data = data.unsqueeze(1)  # Add a new dimension to make broadcasting work\n",
    "    diff = expanded_data - data\n",
    "    dist_matrix = torch.norm(diff, dim=2)  # Compute Euclidean distances\n",
    "\n",
    "    # Convert PyTorch tensor to NumPy for visualization (if needed)\n",
    "    dist_matrix_np = dist_matrix.numpy()\n",
    "\n",
    "    # Plotting the distance matrix\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.imshow(dist_matrix_np, cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar(label='Distance')\n",
    "    plt.title('Distance Matrix')\n",
    "    plt.xticks(ticks=np.arange(len(labels)), labels=labels, rotation=60, ha='right', fontsize=8)  # Replace legends for x-axis\n",
    "    plt.yticks(ticks=np.arange(len(labels)), labels=labels, fontsize=8)\n",
    "    plt.xlabel('Data Index')\n",
    "    plt.ylabel('Data Index')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c073b-0b95-4e0b-8060-0af04a4d76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsl.utils import ProtoTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae45251-f5e2-43e1-b23e-2c683a8837d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsl.tools.prototype_builder import _post_process_prototypes\n",
    "\n",
    "p = _post_process_prototypes('/root/krishneel/Downloads/fsl/prototypes/devit_dinov2_fsod/', 'bg_test.pkl', clean=False, reduction='per_class_cluster', cluster_size=10)\n",
    "\n",
    "print(p.embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1013f3d-2ecf-4b82-bb84-6df130cce601",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1 = ProtoTypes.load('/root/krishneel/Downloads/fsl/prototypes/devit_dinov2_fsod/bg_test.pkl')\n",
    "pt2 = ProtoTypes.load('/root/krishneel/Downloads/fsl/prototypes/dinov2/coco14/background_prototypes_vitb14.pkl')\n",
    "\n",
    "print(pt1.embeddings.shape, pt2.embeddings.shape)\n",
    "\n",
    "plot_tsne(pt1)\n",
    "plot_tsne(pt2)\n",
    "\n",
    "plot_distance(pt1)\n",
    "plot_distance(pt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
