{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febb403-c61e-4ae8-8976-ecab9bcc5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# !pip install git+https://github.com/openai/CLIP timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cca730-6395-49ad-a050-3131d3573df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from igniter.builder import build_engine\n",
    "from fsl.models.meta_arch import build_fsod\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e35d2c2-0a87-449c-91ec-1a894f366e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33m2023-11-09 18:02:01,135 [builder.py:249] WARNING: # TODO: Remove hardcoded name and replace with registry based\u001b[0m\n",
      "/root/krishneel/Documents/github/igniter/igniter/datasets/s3_dataset.py:55: UserWarning: Target transforms is not yet implemented\n",
      "  warnings.warn('Target transforms is not yet implemented')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "config_file = '../configs/devit/resnet_trainval_30shot.yaml'\n",
    "# config_file = '../configs/devit/sam_vitb_trainval_30shot.yaml'\n",
    "\n",
    "cfg = OmegaConf.load(config_file)\n",
    "# print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "cfg.datasets.dataloader.batch_size = 1\n",
    "cfg.datasets.dataloader.num_workers = 0\n",
    "cfg.datasets.dataloader.shuffle=False\n",
    "cfg.options.train = False\n",
    "cfg.options.eval = True\n",
    "cfg.build.resnet_fsod.weights=\"s3://sr-shokunin/perception/models/fsl/resnet_vitb_coco17_30shot/model_0000019.pt\"\n",
    "# cfg.build.sam_fsod.weights = \"s3://sr-shokunin/perception/models/fsl/sam_vitb_coco17_30shot/model_0000001.pt\"\n",
    "\n",
    "engine = build_engine(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ca4f17-e960-436d-beab-9806d02bd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = max([len(iid) for iid in engine._model.classifier._all_cids]) + 1\n",
    "gt_labels = lambda indices: [engine._model.classifier._all_cids[i] for i in indices]\n",
    "\n",
    "def accuracy(scores, gt_names, topk = 1):\n",
    "    _, indices = torch.topk(scores, topk, dim=1)\n",
    "    pred_labels = [gt_labels(index) for index in indices]\n",
    "\n",
    "    count = 0.0\n",
    "    for gt_name, labels in zip(gt_names, pred_labels):\n",
    "        count += 1 if gt_name in labels else 0\n",
    "    return count / len(gt_names)\n",
    "\n",
    "def print_labels(scores, targets, k = 2):\n",
    "    gt_names = targets[0]['gt_proposal'].labels\n",
    "    _, indexes = torch.topk(scores, k, dim=1)\n",
    "    \n",
    "    for name, i in zip(gt_names, indexes.cpu().numpy()):\n",
    "        string = name.ljust(size) + \" | \" + \"\".join([n.ljust(size) for n in gt_labels(i)])\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9111b4d-a334-48fd-af46-372d2be5487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top 1: 0.448 | Top 5 0.673:  60%|██████████████████████████████████▊                       | 2505/4167 [18:05<10:02,  2.76it/s]"
     ]
    }
   ],
   "source": [
    "acc_top1, acc_top5 = 0.0, 0.0\n",
    "progress_bar = tqdm(total=len(engine._dataloader), desc=\"Processing\", position=0, leave=True)\n",
    "\n",
    "for k, (images, targets) in enumerate(engine._dataloader, 1):\n",
    "    with torch.no_grad():\n",
    "        output, _ = engine._model(images, targets)\n",
    "    scores = output['scores']\n",
    "\n",
    "    gt_names = targets[0]['gt_proposal'].labels\n",
    "    t1 = accuracy(scores, gt_names, topk=1)\n",
    "    t5 = accuracy(scores, gt_names, topk=5)\n",
    "\n",
    "    acc_top1 += (t1 - acc_top1) / k\n",
    "    acc_top5 += (t5 - acc_top5) / k\n",
    "\n",
    "    # print(\"\\nImage ID: \", targets[0]['gt_proposal'].image_id)\n",
    "    # print_labels(scores, targets, k=5)\n",
    "    progress_bar.set_description(f\"Top 1: {acc_top1:.3f} | Top 5 {acc_top5:.3f}\")\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "print(\"\\nTop 1: \", acc_top1, \"Top 5: \", acc_top5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
